"""
æ¨¡å‹è¯„ä¼°å’Œé¢„æµ‹
"""

import torch
import torch. nn as nn
import pandas as pd
import numpy as np
from datetime import datetime
import json

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ==================== å¯¼å…¥æ¨¡å‹ç±» ====================
class MultimodalFakeNewsDetector(nn. Module):
    """å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹å™¨"""
    
    def __init__(self, text_feature_dim=4, hidden_dim=128):
        super(MultimodalFakeNewsDetector, self).__init__()
        
        self.text_branch = nn.Sequential(
            nn.Linear(text_feature_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, 64),
            nn.ReLU()
        )
        
        self.image_branch = nn.Sequential(
            nn.Linear(10, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, 64),
            nn.ReLU()
        )
        
        self.fusion = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU()
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 2)
        )
    
    def forward(self, text_features, image_features=None):
        text_out = self.text_branch(text_features)
        
        if image_features is None:
            image_features = torch.randn(text_features.size(0), 10, device=text_features.device)
        
        image_out = self.image_branch(image_features)
        combined = torch.cat([text_out, image_out], dim=1)
        fused = self.fusion(combined)
        output = self.classifier(fused)
        
        return output

# ==================== è¯„ä¼°å™¨ ====================
class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model_path='model_data/best_model.pth'):
        print("="*70)
        print("ğŸ“Š æ¨¡å‹è¯„ä¼°")
        print("="*70)
        
        # åŠ è½½æ¨¡å‹
        self.model = MultimodalFakeNewsDetector()
        self.model.load_state_dict(torch.load(model_path, map_location=device))
        self.model.to(device)
        self.model.eval()
        
        print(f"\nâœ“ æ¨¡å‹å·²åŠ è½½: {model_path}")
    
    def evaluate_on_test_set(self, test_csv):
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°"""
        print(f"\n[1/3] åŠ è½½æµ‹è¯•é›†...")
        
        test_df = pd.read_csv(test_csv)
        print(f"âœ“ æµ‹è¯•é›†å¤§å°: {len(test_df)}")
        
        # å‡†å¤‡æ•°æ®
        text_features = torch.tensor(
            test_df[['title_length', 'text_length', 'score', 'comments']].values,
            dtype=torch.float32
        ).to(device)
        labels = torch.tensor(test_df['label'].values, dtype=torch.long).to(device)
        
        # é¢„æµ‹
        print(f"\n[2/3] è¿›è¡Œé¢„æµ‹...")
        with torch.no_grad():
            outputs = self.model(text_features)
            probabilities = torch. softmax(outputs, dim=1)
            predictions = torch.argmax(outputs, dim=1)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = (predictions == labels).float().mean().item() * 100
        
        print(f"âœ“ é¢„æµ‹å®Œæˆ")
        print(f"\n[3/3] è®¡ç®—æŒ‡æ ‡...")
        
        # è¯¦ç»†æŒ‡æ ‡
        tp = ((predictions == 1) & (labels == 1)).sum().item()
        tn = ((predictions == 0) & (labels == 0)).sum().item()
        fp = ((predictions == 1) & (labels == 0)).sum().item()
        fn = ((predictions == 0) & (labels == 1)).sum().item()
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*70)
        print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
        print("="*70)
        
        print(f"\nå‡†ç¡®ç‡æŒ‡æ ‡:")
        print(f"  å‡†ç¡®ç‡(Accuracy): {accuracy:.2f}%")
        print(f"  ç²¾ç¡®ç‡(Precision): {precision:.2f}")
        print(f"  å¬å›ç‡(Recall): {recall:.2f}")
        print(f"  F1åˆ†æ•°:  {f1:.2f}")
        
        print(f"\næ··æ·†çŸ©é˜µ:")
        print(f"  TP(çœŸæ­£): {tp}")
        print(f"  TN(çœŸè´Ÿ): {tn}")
        print(f"  FP(å‡æ­£): {fp}")
        print(f"  FN(å‡è´Ÿ): {fn}")
        
        return {
            'accuracy': accuracy,
            'precision':  precision,
            'recall': recall,
            'f1':  f1,
            'tp': tp,
            'tn': tn,
            'fp': fp,
            'fn': fn
        }
    
    def predict_samples(self, test_csv, num_samples=5):
        """å¯¹æ ·æœ¬è¿›è¡Œé¢„æµ‹å±•ç¤º"""
        print(f"\n" + "="*70)
        print(f"ğŸ“‹ æ ·æœ¬é¢„æµ‹ (å‰{num_samples}ä¸ª)")
        print("="*70)
        
        test_df = pd.read_csv(test_csv)
        
        for idx in range(min(num_samples, len(test_df))):
            row = test_df.iloc[idx]
            
            # å‡†å¤‡æ•°æ®
            text_features = torch.tensor(
                [[row['title_length'], row['text_length'], row['score'], row['comments']]],
                dtype=torch. float32
            ).to(device)
            
            # é¢„æµ‹
            with torch.no_grad():
                output = self.model(text_features)
                prob = torch.softmax(output, dim=1)[0]
                pred = torch.argmax(output, dim=1)[0].item()
            
            true_label = row['label']
            pred_label = 'çœŸå®' if pred == 1 else 'å…¶ä»–'
            true_label_text = 'çœŸå®' if true_label == 1 else 'å…¶ä»–'
            confidence = prob[pred].item() * 100
            
            print(f"\n[æ ·æœ¬ {idx+1}]")
            print(f"  æ ‡é¢˜: {row['title'][: 60]}")
            print(f"  çœŸå®æ ‡ç­¾: {true_label_text}")
            print(f"  é¢„æµ‹æ ‡ç­¾: {pred_label}")
            print(f"  ç½®ä¿¡åº¦: {confidence:.2f}%")
            print(f"  æ­£ç¡®: {'âœ“' if pred == true_label else 'âœ—'}")

# ==================== ä¸»ç¨‹åº ====================
def main():
    # 1. è¯„ä¼°
    evaluator = ModelEvaluator('model_data/best_model.pth')
    results = evaluator.evaluate_on_test_set('model_data/test_set.csv')
    
    # 2. æ˜¾ç¤ºæ ·æœ¬é¢„æµ‹
    evaluator. predict_samples('model_data/test_set.csv', num_samples=5)
    
    # 3. ä¿å­˜è¯„ä¼°ç»“æœ
    print(f"\n" + "="*70)
    print("âœ… è¯„ä¼°å®Œæˆ!")
    print("="*70)
    
    with open('model_data/evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"âœ“ è¯„ä¼°ç»“æœå·²ä¿å­˜:  model_data/evaluation_results.json")

if __name__ == "__main__":
    main()